{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Metric from Kaggle\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_coefficient(preds,dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'gini', -gini_normalized(y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Faster Gini calculation https://www.kaggle.com/tezdhar/faster-gini-calculation\n",
    "from sklearn import metrics\n",
    "#Remove redundant calls\n",
    "def ginic(actual, pred):\n",
    "    actual = np.asarray(actual) #In case, someone passes Series or list\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
    "    return giniSum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid search from Liguo (for reference only)\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# class CustomGridCV(object):\n",
    "#     def __init__(self, X, y, model, metric, griddata, cv=3):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.model = model\n",
    "#         self.metric = metric\n",
    "#         self.params = self.gridpoints(griddata)\n",
    "#         self.cv = cv\n",
    "#         self.bestScore = None\n",
    "#         self.bestParams = None\n",
    "        \n",
    "#     def gridpoints(self, data):\n",
    "#         newparams = [{}]\n",
    "#         for k in data.keys():\n",
    "#             params = newparams\n",
    "#             newparams = []\n",
    "#             for v in data[k]:\n",
    "#                 for param in params:\n",
    "#                     item = param.copy()\n",
    "#                     item[k]=v\n",
    "#                     newparams.append(item)           \n",
    "#         return newparams\n",
    "    \n",
    "#     def GridSearch(self):\n",
    "#         for param in self.params:\n",
    "#             self.model.set_params(**param)\n",
    "#             score = self.KFoldScore()\n",
    "#             if self.bestScore==None or self.bestScore<score:\n",
    "#                 self.bestScore = score\n",
    "#                 self.bestParams = param\n",
    "#             print(\"Score: {0:.5f}, Params: {1}\".format(score,param))\n",
    "    \n",
    "#     def KFoldScore(self):\n",
    "#         kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "#         y_pred = np.zeros(len(self.y))\n",
    "\n",
    "#         for train_index, test_index in kf.split(self.X):\n",
    "#             train_X, test_X = self.X[train_index], self.X[test_index]\n",
    "#             train_y, test_y = self.y[train_index], self.y[test_index]\n",
    "#             self.model.fit(train_X,train_y)\n",
    "#             y_pred[test_index] = self.model.predict_proba(test_X)[:,1]\n",
    "\n",
    "#         return self.metric(self.y,y_pred)\n",
    "    \n",
    "#     def Best(self):\n",
    "#         return self.bestScore, self.bestParams\n",
    "\n",
    "\n",
    "\n",
    "# Using Grid search tuing hyperParameters:\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Read Data\n",
    "# trainpath = \"E:/datascience/kaggle/porto_seguro/train.csv\"\n",
    "# X, y = PrepareData(trainpath,nrows=10000)\n",
    "\n",
    "# # Select a Model\n",
    "# model = RandomForestClassifier(n_jobs=-1, random_state=1111)\n",
    "\n",
    "# # Set the ranges for parameters\n",
    "# griddata = {\"n_estimators\":[30,50],\n",
    "#             \"max_features\": range(...),\n",
    "#             \"min_samples_leaf\": range(...),\n",
    "#             \"max_depth\": [..]}\n",
    "\n",
    "# # Grid Search for the best parameters\n",
    "# GCV = CustomGridCV(X, y, model, gini_normalized, griddata)\n",
    "\n",
    "# GCV.GridSearch()\n",
    "\n",
    "# print \"Best Params:\"\n",
    "# print GCV.Best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def PrepareData(trainpath,nrows=None):\n",
    "    df = pd.read_csv(trainpath, index_col='id', nrows=nrows)\n",
    "    # feature engineering (from kaggle kernel)\n",
    "    ps_cal = df.columns[df.columns.str.startswith('ps_calc')]\n",
    "    df = df.drop(ps_cal,axis=1)\n",
    "    \n",
    "    # sampling = np.random.choice(595212, replace=False, size=10000)\n",
    "    # df = df.iloc[sampling]\n",
    "\n",
    "    features = list(df.columns)\n",
    "    target = 'target'\n",
    "    features.remove(target)\n",
    "\n",
    "    X = np.array(df[features])\n",
    "    y = np.array(df[target])\n",
    "    return X, y\n",
    "\n",
    "# Read Data\n",
    "trainpath = \"E:/datascience/kaggle/porto_seguro/train.csv\"\n",
    "X, y = PrepareData(trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "from sklearn.svm import SVC\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini_normalizedc(a, p):\n",
    "    if p.ndim == 2:#Required for sklearn wrapper\n",
    "        p = p[:,1] #If proba array contains proba for both 0 and 1 classes, just pick class 1\n",
    "    return ginic(a, p) / ginic(a, a)\n",
    "gini_sklearnf = metrics.make_scorer(gini_normalizedc, True, True)\n",
    "\n",
    "# build extra tree classifier cross validation model\n",
    "def etccv(n_estimators, max_features, max_depth, min_samples_leaf):\n",
    "    val = cross_val_score(\n",
    "        ETC(n_estimators=int(n_estimators),\n",
    "            max_features=int(max_features),\n",
    "            max_depth=int(max_depth),\n",
    "            min_samples_leaf=int(min_samples_leaf)),\n",
    "        X, y, scoring=gini_sklearnf, cv=3\n",
    "    ).mean()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build function to tune hyper_parameters with Bayesian optimization\n",
    "# using prior probability to predict, much faster than Grid search\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "    etcBO = BayesianOptimization(\n",
    "        etccv,\n",
    "        {'n_estimators': (300, 300),\n",
    "         'max_features': (5,10),\n",
    "         'max_depth': (1, 10),\n",
    "         'min_samples_leaf': (100, 100)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    etcBO.maximize(n_iter=10, **gp_params)\n",
    "    print('-' * 53)\n",
    "    print('Final Results')\n",
    "    #print('SVC: %f' % svcBO.res['max']['max_val'])\n",
    "    print('ETC: %f' % etcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running model and Predicting on testing dataset\n",
    "ETC_final=ETC(n_estimators=500, max_features=10, max_depth=10, min_samples_leaf=100, random_state=2, verbose=True, n_jobs=-1)\n",
    "ETC_final.fit(X,y)\n",
    "\n",
    "df_test=pd.read_csv(\"E:/datascience/kaggle/porto_seguro/test.csv\")\n",
    "ps_cal = df_test.columns[df_test.columns.str.startswith('ps_calc')]\n",
    "df_test = df_test.drop(ps_cal,axis=1)\n",
    "features=list(df_test.columns.values)\n",
    "features.remove('id')\n",
    "y_test = ETC_final.predict_proba(df_test[features])\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = df_test['id']\n",
    "subm['target'] = y_test[:,1]\n",
    "subm.to_csv('E:/datascience/kaggle/porto_seguro/mysubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare model data for stacking (from Liguo)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "class Clf4Stack(object):\n",
    "    def __init__(self, model, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.model = model\n",
    "\n",
    "    def fit_predict(self, trainX, trainy, testX):\n",
    "\n",
    "        self.train4stack = np.zeros(len(trainX))\n",
    "        self.test4stack = np.zeros(len(testX))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=44)\n",
    "\n",
    "        for train_index, test_index in skf.split(trainX, trainy):\n",
    "            X_train, X_test = trainX[train_index], trainX[test_index]\n",
    "            y_train, y_test = trainy[train_index], trainy[test_index]\n",
    "\n",
    "            self.model.fit(X_train, y_train)\n",
    "            y_pred = self.model.predict_proba(X_test)[:,1]\n",
    "            self.train4stack[test_index] = y_pred\n",
    "            self.test4stack += self.model.predict_proba(testX)[:,1]\n",
    "        \n",
    "        self.test4stack /= self.n_splits\n",
    "            \n",
    "    def output(self,train_file_name='train4stack.csv',\n",
    "                    test_file_name='test4stack.csv',\n",
    "                    col_name='F4stack'):\n",
    "\n",
    "        pd.DataFrame({col_name:self.train4stack}).to_csv(train_file_name,index=False) \n",
    "        pd.DataFrame({col_name:self.test4stack}).to_csv(test_file_name,index=False)\n",
    "\n",
    "\n",
    "C4S=Clf4Stack(ETC_final)\n",
    "C4S.fit_predict(X, y, df_test[features])\n",
    "C4S.output(train_file_name=\"E:/datascience/kaggle/porto_seguro/train4stack.csv\", \n",
    "           test_file_name=\"E:/datascience/kaggle/porto_seguro/test4stack.csv\", \n",
    "           col_name=\"E:/datascience/kaggle/porto_seguro/F4stack\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
